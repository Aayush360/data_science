{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spelling corrector_word suggestion.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUsYVt2m1YKv3VvZlxJ3eT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aayush360/data_science/blob/master/Spelling_corrector_word_suggestion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvoW044puSi8"
      },
      "source": [
        "fastText is a very convenient technique for building word representations using character- level features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOjg6XbOkL5N",
        "outputId": "f756d98e-8657-478e-cac0-fa5b8f434518"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUfzbmBSolDQ"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from gensim.models import FastText\n",
        "import io\n",
        "import collections\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTuJBcowkQwv"
      },
      "source": [
        "# reading the data into basic structure"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiFy3uW3keLz"
      },
      "source": [
        "words=[]\n",
        "data=[]\n",
        "\n",
        "with open('comments.txt','r') as file:\n",
        "    for entry in file:\n",
        "        entry = entry.strip()\n",
        "        data.append(entry)\n",
        "        words.extend(entry.split())\n",
        "        \n",
        "       "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZCV0TSykgLz",
        "outputId": "b522a360-474a-4027-8510-414373b4cf35"
      },
      "source": [
        "len(words) # there are about 10 million words "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10737835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYjgk7QVlE1T",
        "outputId": "7a60022a-eda7-4b08-ce6d-3b30a75e0883"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "561808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2niLAsClE35"
      },
      "source": [
        "# most common word in the corpus\n",
        "# dictionary of words in the form of key as the words and their frequency as the value"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHiMfS44lE6f",
        "outputId": "2c4e1b44-11dc-4177-c73a-dc12f4395e2b"
      },
      "source": [
        "unique_words = []\n",
        "unique_words = collections.Counter(words)\n",
        "unique_words.most_common(10)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 445892),\n",
              " ('to', 288753),\n",
              " ('of', 219279),\n",
              " ('and', 207335),\n",
              " ('a', 201765),\n",
              " ('I', 182618),\n",
              " ('is', 164602),\n",
              " ('you', 157025),\n",
              " ('that', 140495),\n",
              " ('in', 130244)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E80aYItGlL8X"
      },
      "source": [
        "#  data is dominated by stopwords\n",
        "# preprocessing in terms of keeping only alphanumeric data, case-folding, and removing stopwords.\n",
        "\n",
        "# we dont use stemming or lemmatizing because we want the model to understand incorrect spellings as well"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukCaLl9ClL-0"
      },
      "source": [
        "# let us preprocess the data using the preprocessing pipleline"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KafvpI8ElMBq"
      },
      "source": [
        "def text_clean(corpus):\n",
        "    '''\n",
        "    Purpose : Function to keep only alphabets, digits and certain words (punctuations, qmarks, tabs etc. removed)\n",
        "    \n",
        "    Input : Takes a text corpus, 'corpus' to be cleaned along with a list of words, 'keep_list', which have to be retained\n",
        "            even after the cleaning process\n",
        "    \n",
        "    Output : Returns the cleaned text corpus\n",
        "    \n",
        "    '''\n",
        "    cleaned_corpus = []\n",
        "    for row in corpus:\n",
        "        qs = []\n",
        "        for word in row.split():\n",
        "            p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n",
        "            p1 = p1.lower()\n",
        "            qs.append(p1)\n",
        "        cleaned_corpus.append(' '.join(qs))\n",
        "    return cleaned_corpus"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QYSmJk7lMEL"
      },
      "source": [
        "def stopwords_removal(corpus):\n",
        "    wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
        "    stop = set(stopwords.words('english'))\n",
        "    for word in wh_words:\n",
        "        stop.remove(word) # removing wh words from the set of stopwords\n",
        "    corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n",
        "    return corpus"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lMrVmb4lUNb"
      },
      "source": [
        "def lemmatize(corpus):\n",
        "    lem = WordNetLemmatizer()\n",
        "    corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in corpus]\n",
        "    return corpus"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJEihRzQlUQK"
      },
      "source": [
        "def stem(corpus, stem_type = None):\n",
        "    if stem_type == 'snowball':\n",
        "        stemmer = SnowballStemmer(language = 'english')\n",
        "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
        "    else :\n",
        "        stemmer = PorterStemmer()\n",
        "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
        "    return corpus"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eum-3w34lUTG"
      },
      "source": [
        "def preprocess(corpus, cleaning = True, stemming = False, stem_type = None, lemmatization = False, remove_stopwords = True):\n",
        "    '''\n",
        "    Purpose : Function to perform all pre-processing tasks (cleaning, stemming, lemmatization, stopwords removal etc.)\n",
        "    \n",
        "    Input : \n",
        "    'corpus' - Text corpus on which pre-processing tasks will be performed\n",
        "    'keep_list' - List of words to be retained during cleaning process\n",
        "    'cleaning', 'stemming', 'lemmatization', 'remove_stopwords' - Boolean variables indicating whether a particular task should \n",
        "                                                                  be performed or not\n",
        "    'stem_type' - Choose between Porter stemmer or Snowball(Porter2) stemmer. Default is \"None\", which corresponds to Porter\n",
        "                  Stemmer. 'snowball' corresponds to Snowball Stemmer\n",
        "    \n",
        "    Note : Either stemming or lemmatization should be used. There's no benefit of using both of them together\n",
        "    \n",
        "    Output : Returns the processed text corpus\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    if cleaning == True:\n",
        "        corpus = text_clean(corpus)\n",
        "    \n",
        "    if remove_stopwords == True:\n",
        "        corpus = stopwords_removal(corpus)\n",
        "    else :\n",
        "        corpus = [[x for x in x.split()] for x in corpus]\n",
        "    \n",
        "    if lemmatization == True:\n",
        "        corpus = lemmatize(corpus)\n",
        "        \n",
        "        \n",
        "    if stemming == True:\n",
        "        corpus = stem(corpus, stem_type)\n",
        "    \n",
        "    corpus = [' '.join(x) for x in corpus]        \n",
        "\n",
        "    return corpus"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gve1LJTAlUVl"
      },
      "source": [
        "data = preprocess(data)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3BjiTXClUZE"
      },
      "source": [
        "# data conversion into the format expected by fastText"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbu1wIuLlMHB"
      },
      "source": [
        "preprocessed_data = []\n",
        "for line in data:\n",
        "    if line !=\"\":\n",
        "        preprocessed_data.append(line.split())\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDVVH8qbllbr"
      },
      "source": [
        "# contains list of list of tokens for each sentence \n",
        "preprocessed_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6t5R1B6lleW"
      },
      "source": [
        "## Initialize fastText Model\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bePMdhZ1llgz"
      },
      "source": [
        "# min_n and max_n -- helps us by setting the minimum and maximum lengths of the character\n",
        "# n-grams so that we can build representations"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0YKsKMDlljv"
      },
      "source": [
        "model = FastText(size=300, window=3, min_count=1, min_n=1, max_n=5)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7fq3i5bltXG"
      },
      "source": [
        "# let us build our vocabulary and check the size of the build vocab"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux7M54-LltZ-"
      },
      "source": [
        "model.build_vocab(sentences=preprocessed_data)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRS2orMFltcc",
        "outputId": "e2bb5c88-dfea-4712-9980-fed636f296d4"
      },
      "source": [
        "len(model.wv.vocab)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "182228"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcHXmL_RltfZ"
      },
      "source": [
        "# the size would have been smaller if we would have appiled lemmatization or stemming"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAAtPjXclthp"
      },
      "source": [
        "# let us train our model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFc1rUNyl1kh"
      },
      "source": [
        "model.train(sentences=preprocessed_data,total_examples=len(preprocessed_data),epochs=10)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD9YTPs9l1nV"
      },
      "source": [
        "# check whether our model can actually predict the correct spelling for the incorrect words as part of top 5 similar\n",
        "# suggestion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJtZ08cIr-5j"
      },
      "source": [
        "# took about 11m 29s to train the model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW4BpxAxsBVO",
        "outputId": "7bd096b6-d201-4eed-aa6a-9cb8bd127566"
      },
      "source": [
        "model.wv.most_similar('pnhoe',topn=5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('jjphoto', 0.5202710032463074),\n",
              " ('jpn', 0.5185641050338745),\n",
              " ('phj', 0.5159940719604492),\n",
              " ('phospho', 0.5111843943595886),\n",
              " ('pgj', 0.5102100968360901)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf0XMRKksPWz",
        "outputId": "42c0e845-1d77-4001-c9b2-433b05c1bd80"
      },
      "source": [
        "model.wv.most_similar('eplain',topn=5)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('xplain', 0.8854570388793945),\n",
              " ('eexplain', 0.8442478179931641),\n",
              " ('explain', 0.8437426090240479),\n",
              " ('plain', 0.8350042104721069),\n",
              " ('reexplain', 0.8279873132705688)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbrRzo8HsTqz",
        "outputId": "644302ed-22c3-4431-dffb-486a963fd524"
      },
      "source": [
        "model.wv.most_similar('phon',topn=5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('phonon', 0.9068917632102966),\n",
              " ('phonton', 0.8983222246170044),\n",
              " ('xiphon', 0.8712285757064819),\n",
              " ('zephon', 0.8708957433700562),\n",
              " ('photon', 0.8643317222595215)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hm1FkZSsWqT",
        "outputId": "850afab7-dfe8-4b6f-ee72-df24f060f9d9"
      },
      "source": [
        "model.wv.most_similar('mosue',topn=5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mosque', 0.899060845375061),\n",
              " ('mose', 0.86293625831604),\n",
              " ('mosul', 0.8495413064956665),\n",
              " ('misue', 0.8446767330169678),\n",
              " ('mordue', 0.8430222272872925)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go4v6BqOsaet",
        "outputId": "74ebc4f1-9585-4ec8-c55e-d38639e58c4d"
      },
      "source": [
        "model.wv.most_similar('reminder',topn=5)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('remainder', 0.9125209450721741),\n",
              " ('rejoinder', 0.9104687571525574),\n",
              " ('reindeer', 0.9011728763580322),\n",
              " ('reminde', 0.901120126247406),\n",
              " ('reminders', 0.8968104720115662)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zotzZUWGsfKC",
        "outputId": "346668eb-b673-4038-f03b-cd09b3355a59"
      },
      "source": [
        "model.wv.most_similar('relevnt',topn=5)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('relevant', 0.8275952935218811),\n",
              " ('relev', 0.8186317682266235),\n",
              " ('relevanmt', 0.7933294177055359),\n",
              " ('releveant', 0.7883942127227783),\n",
              " ('releant', 0.7858115434646606)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkwsniBzslDz"
      },
      "source": [
        "# Our fastText model does a good job in terms of suggesting corrections and potential alternatives for input text"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnaowoD0s30m"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq2beOrvtalG"
      },
      "source": [
        "### FastText and document distances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHDux1uftBcc"
      },
      "source": [
        "# built for spelling correction to check for document distances using the Word Mover's Distance (WMD) algorithm."
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilIIoc3PtHvM"
      },
      "source": [
        "sentence_1 = 'Obama speaks to the media in Illinios.'\n",
        "sentence_2 = 'President greets the press in Chicago'\n",
        "sentence_3 ='Apple is my favorite comapany'"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fObXxk-tZtW"
      },
      "source": [
        "# let us compute the distance between the doucment pairs using WMD\n",
        "# using fastText based vectors"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDYtXzOUtoT-",
        "outputId": "409280cc-558d-4bd7-ec6d-b1fbd0706c55"
      },
      "source": [
        "word_mover_distance = model.wmdistance(sentence_1,sentence_2)\n",
        "word_mover_distance"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wmdistance` (Method will be removed in 4.0.0, use self.wv.wmdistance() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.7337269612388"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBCAsq0pt20R",
        "outputId": "1726a81b-fa3c-40e7-91d4-c8db8797c541"
      },
      "source": [
        "word_mover_distance = model.wmdistance(sentence_2,sentence_3)\n",
        "word_mover_distance"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wmdistance` (Method will be removed in 4.0.0, use self.wv.wmdistance() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.90574322915053"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFvilLlxt7sG"
      },
      "source": [
        "# sentence 1 and sentence 2 as smaller distance compared to 2 and 3"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAi_rCkEuD0E"
      },
      "source": [
        "# The results that we obtained in the spelling correction and distance calculations would be potentially better \n",
        "# if pre-trained fastText models were used since those are mostly built on Wikipedia text corpora and are more \n",
        "# generalized to understand different data points."
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCDpuwqpuNM-"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xx9IOOQukz6"
      },
      "source": [
        "pickle.dump(model, open('fasttext_model.sav','wb'))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TT18XtDut2e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}