{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_level_language_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPL56fHx6WPAKPrA9QNTzGB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aayush360/data_science/blob/master/word_level_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyTaJUoxRFSr",
        "colab_type": "text"
      },
      "source": [
        "##  Making a word level language model (implementation of RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMpbjSajPYsL",
        "colab_type": "text"
      },
      "source": [
        "#  [Source:](https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBnjk5jU87sR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import dependencies\n",
        "\n",
        "import string\n",
        "from pickle import dump,load\n",
        "import numpy as np\n",
        "from random import randint\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISQ0-1VuPh8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load document into memory\n",
        "\n",
        "def load_doc(filename):\n",
        "  # open the filename in readonly mode\n",
        "  file = open(filename,'r')\n",
        "  # read all the content in the file\n",
        "  text = file.read()\n",
        "  file.close()\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5ituAAXRXOK",
        "colab_type": "code",
        "outputId": "da7ddb5a-c629-4142-cfd3-ad8ab7bc30a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# load the document\n",
        "in_filename ='/content/republic.txt'\n",
        "doc = load_doc(in_filename)\n",
        "print(doc[:200])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOOK I.\n",
            "\n",
            "I went down yesterday to the Piraeus with Glaucon the son of Ariston,\n",
            "that I might offer up my prayers to the goddess (Bendis, the Thracian\n",
            "Artemis.); and also because I wanted to see in what\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbwdpnE_vp7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cleaning the text\n",
        "\n",
        "def clean_doc(doc):\n",
        "  # replace -- with ' '\n",
        "  doc = doc.replace('--',' ')\n",
        "  # split into tokens by whitespace\n",
        "  tokens = doc.split()\n",
        "  # remove punctuations form each token\n",
        "  table = str.maketrans('','',string.punctuation)\n",
        "  tokens = [w.translate(table) for w in tokens]\n",
        "  # remove remaining tokens that are not alphabetic\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  # make lowercase\n",
        "  tokens = [ word.lower() for word in tokens]\n",
        "  return tokens\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2OBwl5HBmPV",
        "colab_type": "code",
        "outputId": "778222a5-e207-453d-8901-e97aa9d8c2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# clean document\n",
        "tokens = clean_doc(doc)\n",
        "print(tokens[:200])\n",
        "print('total tokens are: ', len(tokens))\n",
        "print('total unique tokens are: ', len(set(tokens)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['book', 'i', 'i', 'went', 'down', 'yesterday', 'to', 'the', 'piraeus', 'with', 'glaucon', 'the', 'son', 'of', 'ariston', 'that', 'i', 'might', 'offer', 'up', 'my', 'prayers', 'to', 'the', 'goddess', 'bendis', 'the', 'thracian', 'artemis', 'and', 'also', 'because', 'i', 'wanted', 'to', 'see', 'in', 'what', 'manner', 'they', 'would', 'celebrate', 'the', 'festival', 'which', 'was', 'a', 'new', 'thing', 'i', 'was', 'delighted', 'with', 'the', 'procession', 'of', 'the', 'inhabitants', 'but', 'that', 'of', 'the', 'thracians', 'was', 'equally', 'if', 'not', 'more', 'beautiful', 'when', 'we', 'had', 'finished', 'our', 'prayers', 'and', 'viewed', 'the', 'spectacle', 'we', 'turned', 'in', 'the', 'direction', 'of', 'the', 'city', 'and', 'at', 'that', 'instant', 'polemarchus', 'the', 'son', 'of', 'cephalus', 'chanced', 'to', 'catch', 'sight', 'of', 'us', 'from', 'a', 'distance', 'as', 'we', 'were', 'starting', 'on', 'our', 'way', 'home', 'and', 'told', 'his', 'servant', 'to', 'run', 'and', 'bid', 'us', 'wait', 'for', 'him', 'the', 'servant', 'took', 'hold', 'of', 'me', 'by', 'the', 'cloak', 'behind', 'and', 'said', 'polemarchus', 'desires', 'you', 'to', 'wait', 'i', 'turned', 'round', 'and', 'asked', 'him', 'where', 'his', 'master', 'was', 'there', 'he', 'is', 'said', 'the', 'youth', 'coming', 'after', 'you', 'if', 'you', 'will', 'only', 'wait', 'certainly', 'we', 'will', 'said', 'glaucon', 'and', 'in', 'a', 'few', 'minutes', 'polemarchus', 'appeared', 'and', 'with', 'him', 'adeimantus', 'glaucons', 'brother', 'niceratus', 'the', 'son', 'of', 'nicias', 'and', 'several', 'others', 'who', 'had', 'been', 'at', 'the', 'procession', 'polemarchus', 'said']\n",
            "total tokens are:  118684\n",
            "total unique tokens are:  7409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SxKfCwdCDyY",
        "colab_type": "code",
        "outputId": "39073d63-b2a0-4d7f-ab4e-ae11aba97f9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# organize into sequences of tokens\n",
        "\n",
        "length = 50 + 1\n",
        "sequences = list()\n",
        "for i in range(length, len(tokens)):\n",
        "  # select sequence of tokens\n",
        "  seq = tokens[i-length:i]\n",
        "  # convert into a line\n",
        "  line = ' '.join(seq)\n",
        "  #store\n",
        "  sequences.append(line)\n",
        "\n",
        "print('total sequences is: %d' % len(sequences))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total sequences is: 118633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP1vY3ZqEIdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save tokens to file, one dialoge per line\n",
        "def save_doc(lines,filename):\n",
        "  data ='\\n'.join(lines)\n",
        "  file = open(filename,'w')\n",
        "  file.write(data)\n",
        "  file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTm3BUdcExbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save sequences to file\n",
        "out_filename ='republic_sequences.txt'\n",
        "save_doc(sequences, out_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8rrJj7TMQIh",
        "colab_type": "text"
      },
      "source": [
        "### Train Language Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3XT4vuWFAc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load\n",
        "in_filename = '/content/republic_sequences.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjrSWdCxMaVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#integer encode sequences of words\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZc-FnCnkQ7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MRLORmSjrrc",
        "colab_type": "code",
        "outputId": "5c92dd2c-b437-4ca9-8184-3a020474b7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#vocabulary size\n",
        "'''The Embedding layer needs to allocate a vector representation for each word in this vocabulary \n",
        "  from index 1 to the largest index and because indexing of arrays is zero-offset, \n",
        "  the index of the word at the end of the vocabulary will be 7,409; that means the \n",
        "  array must be 7,409 + 1 in length.'''\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "vocab_size"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7410"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBi_llmSj3nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# separate into input and output\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1] # since we have added 1 to vocab size that starts with indexing of 0\n",
        "y = to_categorical(y, num_classes= vocab_size)\n",
        "seq_length = X.shape[1] # specify the number of columns i,e 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQlHdr3LstNW",
        "colab_type": "text"
      },
      "source": [
        "## Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWMlSoU0lYNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ed0cc4bd-474e-4c02-93f4-cdd1ba0f544c"
      },
      "source": [
        "'''A dense fully connected layer with \n",
        "100 neurons connects to the LSTM hidden layers to \n",
        "interpret the features extracted from the sequence'''\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A dense fully connected layer with \\n100 neurons connects to the LSTM hidden layers to \\ninterpret the features extracted from the sequence'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TJ7MXbumuxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "aaadf017-8bcc-41df-9e25-a1e93f099ff7"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            370500    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7410)              748410    \n",
            "=================================================================\n",
            "Total params: 1,269,810\n",
            "Trainable params: 1,269,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpEzaGSLmy29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "993d245f-428f-49d2-d93d-c7eaebf43b70"
      },
      "source": [
        "# compile the model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "\n",
        "model.fit(X,y, batch_size=128, epochs=100)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 6.1471 - accuracy: 0.0724\n",
            "Epoch 2/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 5.6643 - accuracy: 0.1083\n",
            "Epoch 3/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 5.4171 - accuracy: 0.1340\n",
            "Epoch 4/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 5.2602 - accuracy: 0.1465\n",
            "Epoch 5/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 5.1398 - accuracy: 0.1547\n",
            "Epoch 6/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 5.0387 - accuracy: 0.1604\n",
            "Epoch 7/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.9498 - accuracy: 0.1662\n",
            "Epoch 8/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.8700 - accuracy: 0.1707\n",
            "Epoch 9/100\n",
            "927/927 [==============================] - 14s 16ms/step - loss: 4.7911 - accuracy: 0.1754\n",
            "Epoch 10/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.7178 - accuracy: 0.1787\n",
            "Epoch 11/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.6471 - accuracy: 0.1822\n",
            "Epoch 12/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.5890 - accuracy: 0.1858\n",
            "Epoch 13/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.5242 - accuracy: 0.1886\n",
            "Epoch 14/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.4652 - accuracy: 0.1911\n",
            "Epoch 15/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.4099 - accuracy: 0.1936\n",
            "Epoch 16/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.3561 - accuracy: 0.1962\n",
            "Epoch 17/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.3067 - accuracy: 0.1991\n",
            "Epoch 18/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 4.2590 - accuracy: 0.2015\n",
            "Epoch 19/100\n",
            "927/927 [==============================] - 14s 16ms/step - loss: 4.2144 - accuracy: 0.2029\n",
            "Epoch 20/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 4.1724 - accuracy: 0.2063\n",
            "Epoch 21/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 4.1325 - accuracy: 0.2090\n",
            "Epoch 22/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 4.0942 - accuracy: 0.2121\n",
            "Epoch 23/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 4.0583 - accuracy: 0.2148\n",
            "Epoch 24/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 4.0244 - accuracy: 0.2176\n",
            "Epoch 25/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.9914 - accuracy: 0.2209\n",
            "Epoch 26/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.9612 - accuracy: 0.2231\n",
            "Epoch 27/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.9317 - accuracy: 0.2260\n",
            "Epoch 28/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.9025 - accuracy: 0.2296\n",
            "Epoch 29/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.8756 - accuracy: 0.2319\n",
            "Epoch 30/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.8482 - accuracy: 0.2338\n",
            "Epoch 31/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.8238 - accuracy: 0.2363\n",
            "Epoch 32/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.7976 - accuracy: 0.2405\n",
            "Epoch 33/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.7727 - accuracy: 0.2416\n",
            "Epoch 34/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.7474 - accuracy: 0.2459\n",
            "Epoch 35/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.7270 - accuracy: 0.2473\n",
            "Epoch 36/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.7018 - accuracy: 0.2497\n",
            "Epoch 37/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.6779 - accuracy: 0.2528\n",
            "Epoch 38/100\n",
            "927/927 [==============================] - 14s 16ms/step - loss: 3.6565 - accuracy: 0.2563\n",
            "Epoch 39/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.6342 - accuracy: 0.2584\n",
            "Epoch 40/100\n",
            "927/927 [==============================] - 14s 16ms/step - loss: 3.6141 - accuracy: 0.2610\n",
            "Epoch 41/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.5920 - accuracy: 0.2636\n",
            "Epoch 42/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.5717 - accuracy: 0.2667\n",
            "Epoch 43/100\n",
            "927/927 [==============================] - 14s 16ms/step - loss: 3.5515 - accuracy: 0.2683\n",
            "Epoch 44/100\n",
            "927/927 [==============================] - 14s 16ms/step - loss: 3.5307 - accuracy: 0.2714\n",
            "Epoch 45/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.5098 - accuracy: 0.2753\n",
            "Epoch 46/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 3.4903 - accuracy: 0.2769\n",
            "Epoch 47/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 3.4711 - accuracy: 0.2804\n",
            "Epoch 48/100\n",
            "927/927 [==============================] - 16s 17ms/step - loss: 3.4540 - accuracy: 0.2828\n",
            "Epoch 49/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.4355 - accuracy: 0.2837\n",
            "Epoch 50/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.4134 - accuracy: 0.2866\n",
            "Epoch 51/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.3993 - accuracy: 0.2893\n",
            "Epoch 52/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.3777 - accuracy: 0.2920\n",
            "Epoch 53/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.3607 - accuracy: 0.2947\n",
            "Epoch 54/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.3444 - accuracy: 0.2976\n",
            "Epoch 55/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.3235 - accuracy: 0.3001\n",
            "Epoch 56/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.3087 - accuracy: 0.3025\n",
            "Epoch 57/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.2906 - accuracy: 0.3052\n",
            "Epoch 58/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.2742 - accuracy: 0.3076\n",
            "Epoch 59/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.2586 - accuracy: 0.3099\n",
            "Epoch 60/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.2423 - accuracy: 0.3120\n",
            "Epoch 61/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.2245 - accuracy: 0.3149\n",
            "Epoch 62/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.2100 - accuracy: 0.3167\n",
            "Epoch 63/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.1956 - accuracy: 0.3186\n",
            "Epoch 64/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.1796 - accuracy: 0.3214\n",
            "Epoch 65/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.1616 - accuracy: 0.3240\n",
            "Epoch 66/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.1496 - accuracy: 0.3265\n",
            "Epoch 67/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.1334 - accuracy: 0.3284\n",
            "Epoch 68/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.1185 - accuracy: 0.3314\n",
            "Epoch 69/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.1035 - accuracy: 0.3334\n",
            "Epoch 70/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.0876 - accuracy: 0.3348\n",
            "Epoch 71/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.0725 - accuracy: 0.3386\n",
            "Epoch 72/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.0585 - accuracy: 0.3397\n",
            "Epoch 73/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.0436 - accuracy: 0.3429\n",
            "Epoch 74/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.0301 - accuracy: 0.3452\n",
            "Epoch 75/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.0138 - accuracy: 0.3478\n",
            "Epoch 76/100\n",
            "927/927 [==============================] - 15s 16ms/step - loss: 3.0001 - accuracy: 0.3495\n",
            "Epoch 77/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.9866 - accuracy: 0.3514\n",
            "Epoch 78/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.9742 - accuracy: 0.3534\n",
            "Epoch 79/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.9604 - accuracy: 0.3563\n",
            "Epoch 80/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.9455 - accuracy: 0.3576\n",
            "Epoch 81/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.9309 - accuracy: 0.3601\n",
            "Epoch 82/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.9178 - accuracy: 0.3630\n",
            "Epoch 83/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.9042 - accuracy: 0.3651\n",
            "Epoch 84/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.8887 - accuracy: 0.3684\n",
            "Epoch 85/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.8768 - accuracy: 0.3711\n",
            "Epoch 86/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.8631 - accuracy: 0.3715\n",
            "Epoch 87/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.8501 - accuracy: 0.3747\n",
            "Epoch 88/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.8350 - accuracy: 0.3774\n",
            "Epoch 89/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.8229 - accuracy: 0.3785\n",
            "Epoch 90/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.8074 - accuracy: 0.3817\n",
            "Epoch 91/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.7962 - accuracy: 0.3840\n",
            "Epoch 92/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.7849 - accuracy: 0.3855\n",
            "Epoch 93/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.7720 - accuracy: 0.3890\n",
            "Epoch 94/100\n",
            "927/927 [==============================] - 14s 16ms/step - loss: 2.7586 - accuracy: 0.3889\n",
            "Epoch 95/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.7433 - accuracy: 0.3938\n",
            "Epoch 96/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.7321 - accuracy: 0.3951\n",
            "Epoch 97/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.7185 - accuracy: 0.3969\n",
            "Epoch 98/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.7098 - accuracy: 0.3994\n",
            "Epoch 99/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.6969 - accuracy: 0.4009\n",
            "Epoch 100/100\n",
            "927/927 [==============================] - 14s 15ms/step - loss: 2.6832 - accuracy: 0.4030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe220df5160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ZioML3-Hob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to file\n",
        "\n",
        "model.save('/content/model.h5')\n",
        "\n",
        "# save the tokenizer\n",
        "\n",
        "dump(tokenizer, open('tokenizer.pkl','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIntxxor--or",
        "colab_type": "text"
      },
      "source": [
        "### Use Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UYGrwNT-xII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4ba1b0a-de1e-4f05-b02b-90ff2bd29a3b"
      },
      "source": [
        "'''we can use it to generate new sequences of text that have the same statistical properties as the source text.'''"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'we can use it to generate new sequences of text that have the same statistical properties as the source text.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjktFVgQ_Dg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = len(lines[0].split()) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bl7dcls_1eb",
        "colab_type": "text"
      },
      "source": [
        "### Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHv-VlX1_kIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3887160d-c965-4113-e157-4df587ce6f60"
      },
      "source": [
        "# load the model\n",
        "\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G052LRgl_-dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the tokenizer\n",
        "\n",
        "tokenizer = load(open('tokenizer.pkl','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N-JjoWrA1L_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6775ce24-c2ac-4535-b459-78a869e73d29"
      },
      "source": [
        "# select a seed\n",
        "\n",
        "seed_text = lines[randint(0,len(lines))]\n",
        "print(seed_text+'\\n')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "any other disease or the knife put to the throat or even the cutting up of the whole body into the minutest pieces can destroy the soul until she herself is proved to become more unholy or unrighteous in consequence of these things being done to the body but that the\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z283LopEB3OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbk9510TCwhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ef41540d-6661-42e8-fe4d-dec0dcd6927a"
      },
      "source": [
        "\n",
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
        "print(generated)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-61-c33a756b573f>:11: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "other is the goods of life is not the most royal man and not to be the best limit the other and heaviest and again has not the most trustworthy assuredly and i must endeavour to explain i said that the shepherd and creates lies to drink and in the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgRutD5yDx0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}